## 5.4 봉화희제후와 메모리 장벽

<aside>

봉화희제후란, 중국의 양치기 소년 이야기

Thread 사이의 동기화 시 비순차적인 동작 가능

[예시1]

```cpp
bool is_enemy_coming = false;
int enemy_num = 0;

// 주유왕 스레드
void thread_zhouyouwang()
{
	enemy_num = 10000;
	is_enemy_coming = true;
}

// 제후 스레드
void thread_zhuhou()
{
	int n;
	
	if (is_enemy_coming) 
	{
		n = enemy_num;
	}
}
```

위 코드에서 많은 사람이 n = 10000이라 답하지만, 실제로 0일 수 있음

단, 이러한 상황은 x86 플랫폼에서 발생하지 않음

[예시2] 두 전역 변수 X와 Y 초깃값은 모두 0

```cpp
//스레드1
X = 1;
a = Y;
```

```cpp
//스레드2
Y = 1;
b = X;
```

스레드의 동작 순서에 따라 아래와 같은 결과 나타남

- 스레드1이 먼저 실행 → a=0, b=1
- 스레드2가 먼저 실행 → a=1, b=0
- 동시에 실행 → a=1,b=1
- x86 플랫폼의 경우 가능 → a=0, b=0
</aside>

### 5.4.1 명령어의 비순차적 실행: 컴파일러와 OoOE

> “CPU는 반드시 엄격하게 프로그래머가 코드를 작성한 순서대로 명령어를 실행하지 않음”
1. 기계 명령어 생성 시 명령어 재정렬로 비순차적 실행 가능
2. CPU가 명령어 실행 시 비순차적으로 실행 가능
> 

**명령어의 비순차적 실행 단계**

1. 기계 명령어 생성
    1. 컴파일 중 명령어 재정렬
2. CPU가 명령어 실행
    1. 실행 중에 명령어가 비순차적으로 실행
 

**1. 컴파일러의 명령어 재정렬**

1. 코드

```cpp
int a;
int b;

void main()
{
	a = b+100;
	b = 200;
}
```

1. 컴파일된 어셈블리어
    
    컴파일러 종류 ⇒ gcc 기본 컴파일 옵션&objdump 사용
    
    - `gcc main.c -o main`
    - +) [gcc & objdump](https://www.notion.so/gcc-objdump-1f7deb6219af8064995de32881d19f89?pvs=21)
    
    | mov | 0x200b54(%rip), %eax | # %eax = b |
    | --- | --- | --- |
    | add | $0x64, %eax | # %eax = %eax + 100 |
    | mov | %eax, 0x200b4f(%rip) | # a = $eax |
    | movl | $0xc8, 0x200b41(%rip) | # b = 200 |
2. 컴파일된 어셈블리어
    
    컴파일러 종류 ⇒ gcc 기본 컴파일 -O2 적용
    
    - `-O2` 는 컴파일러가 코드를 최적화할 수 있도록 함
    - `gcc -O2 main.c -o main`
    
    | mov | 0x200b54(%rip), %eax | # %eax = b |
    | --- | --- | --- |
    | movl | $0xc8, 0x200b41(%rip) | # b = 200 |
    | add | $0x64, %eax | # %eax = %eax + 100 |
    | mov | %eax, 0x200b4f(%rip) | # a = $eax |
    
    ⭐ 이때 컴파일러가 b=200 코드 줄을 `a = b+1` 코드 줄 앞에 놓음
    
    오류가 나지 않는 이유는 eax 레지스터가 b 변수의 초기값인 100을 저장하고 있음
    

위가 컴파일동안 명령어 재정렬하는 동작! 

일반적으로 해당 코드 추가해 명령어 재정렬하지 않도록 지시 가능 ⇒ `asm volatile("" ::: "memory");`

**2. CPU 명령어 실행 시 비순차적 실행**

기존 CPU 과정

1. 기계 명령어(opcode) 가져옴
2. 명령어의 피연산자(operand)가 레지스터에 저장되는 등 이미 준비 완료 상태라면 명령어 실행. 명령어의 피연산자가 아직 메모리에서 레지스터로 저장되지 않아 준비가 완료되지 않으면 대기
3. 데이터가 준비되었다면 명령어 실행
4. 실행 결과 기록

⇒ 피연산자가 준비되지 않은 경우 CPU가 반드시 대기해야 하므로 비효율적

개선된 CPU 과정

1. 기계 명령어(opcode) 가져옴
2. 명령어를 대기열(reservation station)에 넣고 명령어에 필요한 피연산자 읽음
3. 명령어는 대기열에서 피연산자의 준비가 완료될 때까지 대기. 준비 완료된 명령어가 먼저 실행
4.  기계 명령어를 실행하면 실행 결과를 대기열에 넣음
5. 이전 명령어의 실행 결과가 기록될 때까지 대기하다가 현재 명령어의 실행 결과 기록. 명령어의 원래 실행 순서에 따라 유효한 결과를 얻기 위한 목적

⇒ 이 과정에서 명령어 실행이 엄격한 순서로 진행되지 않음을 알 수 있으며 이것이 비순차적 명령어 처리(Out of Order Execution, OoOE)

따라서 CPU와 메모리 사이의 속도 차이로 인해 피연산자를 기다리는 동안 “빈 공간”인 슬롯(slot)을 “준비 완료된 다른 명령어”로 메꿀 수 있다면 명령어의 실행 속도 향상 가능

BUT 전후 관계의 두 명령어가 서로 어떤 의존 관계가 없을 때에 한하여 동작하며, 모든 CPU가 비순차적 명령어 실행 기능을 가지지 않음

### 5.4.2 캐시도 고려해야 한다

> 캐시와 비순차적 실행
> 

**캐시**

각 CPU 코어마다 L1 캐시와 L2 캐시가 별도로 존재하며, L3 캐시와 메모리는 모든 코어가 공유


**캐시 일관성 유지 문제**

캐시가 있는 모든 시스템은 캐시를 갱신하고 캐시의 일관성 유지시키는 문제 마주함

이 작업 전에 CPU는 반드시 대기 상태를 중지해야 하며, 이 과정을 최적화하기 위해 저장 버퍼(store buffer) 등 대기열 추가 ⇒ 명령어 실행 속도 향상

- 기록 작업이 있을 때 대기열에 직접 기록하기 때문에 캐시는 즉시 갱신되지 않고, CPU는 캐시가 갱신되기를 기다리지 않고 다음 명령어 계속 실행 가능


CPU가 실행하는 명령어와 비교할 때 기록 작업은 비동기 과정

- CPU는 기록 작업이 캐시와 메모리를 갱신할 때까지 기다리지 않고 다음 명령어 실행
- 비동기 케이스
    - a 변수의 초깃값 0, b 변수의 초깃값 100이라 가정
    - 코드
        
        ```c
        a = 1;
        b = y;
        ```
        
    - CPU 코어 A가 `a=1` 실행할 때 1이라는 데이터는 코어 A 캐시에 갱신되지 않았지만 저장 버퍼에 존재. 갱신되기를 기다릴 필요 없이 다음 줄인 `b=y` 실행 가능 ⇒ 이때 b=100
    - BUT 또다른 CPU 코어 B가 b 값이 100임을 인지하는 시점에 a 값은 코어 B 입장에서 볼 때 여전히 초깃값인 0일 가능성 존재 ⇒ 캐시와 메모리가 갱신되지 않았기 때문
        - 따라서 두 번째 코드가 먼저 실행되고, 첫번째 코드가 실행된 것처럼 보일 수 있음
    - 하지만 CPU 설계가 순차적 실행을 보장하기 때문에 해당 스레드 내부에서는 비순차적 실행을 볼 수 없음
        
        ```c
        a = 1;
        b = y;
        
        print(a);
        ```
        
- 즉, 이 비순차적 실행은 자기 자신 이외의 또 다른 코어가 해당 코어를 바라볼 때만 나타나는 현상
- 단일 스레드 환경에서 프로그래밍하는 경우, 근본적으로 이 문제를 신경쓸 필요 없음

**잠금 없는 프로그래밍(lock-free programming)**

잠금 없는 프로그래밍: 잠금을 통한 보호를 사용하지 않는 상태에서 다중 스레드의 공유 리소스를 처리하는 것

일반적으로 다중 스레드에서 공유 리소스를 사용하는 작업은 잠금을 통한 보호 필요

**명령어의 비순차적 실행 문제 해결 방법: Memory barrier**

Memory barrier(메모리 장벽): 특정 코어가 다른 코어를 보았을 때 값이 일치하도록 하는 것

명령어는 비순차적으로 실행될 수 있지만, Memory barrier 기계 명령어를 통해 스레드의 CPU 코어에 아래 명령 내릴 수 있음

- “순서에 맞춰 실행하여 다른 코어가 이 코어를 보았을 때 비순차적 명령어를 실행하는 것으로 보이면 안 됨”

Memory는 읽기(Load)와 쓰기(Store) 작업만 존재

- 따라서 메모리 장벽 유형은 LoadLoad, StoreStore, LoadStore, StoreLoad 존재하며, 모두 비순차적 실행을 금지한다는 의미

### 5.4.3 네 가지 메모리 장벽 유형

> 명령어가 비순차적으로 실행되지 않도록 하는 4가지 방법
> 
1. **LoadLoad**
    
    CPU가 Load 명령어를 실행할 때 다음에 오는 Load 명령어가 먼저 실행되는 것 방지
    
    앞선 예시에서 is_enemy_coming과 enemy_num 변수를 읽을 때 
    
    - 제후 스레드가 enemy_num을 먼저 읽을 가능성 있음. 이때 enemy_num은 0이고 is_enemy_coming은 true라 “예전의” enemy_num을 읽을 수 있음
    - 이를 해결하기 위해 if 문에서 n값을 설정하기 전 LoadLoad 메모리 장벽을 추가해 재정렬 방지
    
    
2. **StoreStore**
    
    CPU가 Store 명령어 실행할 때 다음에 오는 Store 명령어가 먼저 실행되는 것 방지
    
    앞선 예시( [bool is_enemy_coming = false;
    int enemy_num = 0;
    
    // 주유왕 스레드
    void thread_zhouyouwang()
    {
    	enemy_num = 10000;
    	is_enemy_coming = true;
    }
    
    // 제후 스레드
    void thread_zhuhou()
    {
    	int n;
    	
    	if (is_enemy_coming) 
    	{
    		n = enemy_num;
    	}
    }](https://www.notion.so/bool-is_enemy_coming-false-int-enemy_num-0-void-thread_zhouyouwang-enemy_num--1f7deb6219af80c2a7c5ed1a1371e52c?pvs=21))에서 is_enemy_coming과 enemy_num 변수를 앞뒤 연속적으로 설정해야 함
    
    - 앞의 enemy_num보다 뒤의 is_enemy_coming 변수를 먼저 설정할 가능성 있음
    - 이를 해결하기 위해 두 변수 값 설정하는 중간에 StoreStore 메모리 장벽 추가해 신호 우선 설정 방지
    
    시스템에 캐시가 추가되면 비동기적으로 처리될 수 있지만, StoreStore 메모리 장벽을 추가해 다른 코어에서도 코드 순서대로 동작하도록 함
    
    
3. **LoadStore**
    
    CPU가 Load 명령어 실행보다 뒤의 Store 명령어를 먼저 실행하는 것 방지
    
    ❓ 쓰기(Store) 작업은 읽기(Load)보다 상대적으로 무거운데 어떻게 먼저 실행될 수 있을까?
    
    → Load 명령어가 캐시에 적중하지 못하면 일부 CPU가 다음에 오는 Store 명령어 먼저 실행할 수 있음
    
    ```c
    // 제후 스레드
    void thread_zhuhou()
    {
    	int n;
    	int important;
    	
    	if (is_enemy_coming)
    	{
    		LoadLoad_FENCE(); // LoadLoad 메모리 장벽
    		
    		n = enemy_num;
    		
    		// LoadStore 메모리 장벽 추가 => LoadLoad 메모리 장벽만으로는 부족
    		
    		important = 10; // 반드시 봉화 신호(앞의 모든 Load)가 보일 때까지 기다려야 실행 가능
    	}
    }
    ```
    
    
4. **StoreLoad**
    
    쓰기(Store) 명령어를 실행할 때 CPU가 읽기(Load) 명령어를 먼저 실행하는 것 방지
    
    이 메모리 장벽이 4가지 메모리 장벽 중 가장 “무거움”
    
    - CPU가 쓰기 명령어를 실행할 때 해당 쓰기 명령어에 필요한 작업이 완료될 때까지 다음에 오는 읽기 작업을 미리 실행할 수 없음
    
    StoreLoad vs StoreStore
    
    - StoreStore는 장벽 실행 후 다른 코어가 메모리 장벽 이전의 변수를 읽을 때 최신 값임을 보장하지 않음
    - 반면에 StoreLoad는 장벽 이전에 쓰기 작업이 모든 다른 코어에서 반드시 확인 가능해야 함
        
        ⇒ 해당 장벽 실행 전 변수가 최신 값임을 보장
        
        ⇒ “동기 작업”
        
    
    아래 코드에서 a=0, b=0인 상황이 나타나지 않음을 유일하게 보장하는 메모리 장벽 
    
    ```c
    // Thread1
    X = 1;
    StoreLoad();
    a = Y;
    
    // Thread2
    Y = 1;
    StoreLoad();
    b = X;
    ```
    

CPU가 비순차적 실행을 방지하기 위해 여러 메모리 장벽을 사용하는 것은 번거로움

⇒ 획득-해제 의미론으로 간단히 해결 가능

### 5.4.4 획득-해제 의미론

> 획득-해제 의미론을 활용한 스레드 간 동기화 문제 해결
> 

**획득-해제 의미론**

다중 스레드 프로그래밍 시 발생하는 “스레드 간 동기화 문제”를 해결하기 위해 사용

**획득 의미론**

메모리 읽기 작업에 대한 것

Load 뒤에 있는 모든 메모리 작업은 이 Load 작업 이전에는 실행 불가능

- 즉, Load → Load/Store 순서



**해제 의미론**

메모리 쓰기 작업에 대한 것

이번 Store 앞에 있는 모든 메모리 작업은 이 Store 작업 이후에는 실행 불가능

- 즉, Load/Store → Store 순서



**획득-해제 의미론**

LoadLoad와 LoadStore 조합 ⇒ 획득 의미론

StoreStore와 LoadStore 조합 ⇒ 해제 의미론

이때 무거운 StoreLoad 메모리 장벽이 필요하지 않음 !

앞선 예시에서 주유왕 스레드에 해제 의미론 사용하고, 제후 스레드에 획득 의미론 사용해 스레드 동기화 문제 해결

### 5.4.5 C++에서 제공하는 인터페이스

> C++에서의 획득-해제 의미론 구현
> 

**이식성 높은 프로그래밍** 

서로 다른 유형의 CPU는 서로 다른 기질과 천성을 가져 특정 유형의 CPU만 대상으로 코드를 작성하면 이식성이 떨어짐

따라서 언어 수준에서 제공하는 획득-해제 의미론 사용

ex. C++11의 atomic 원자 라이브러리 코드

```cpp
#include <atomic>

std::atomic_thread_fence(std::memory_order_acquire);
std::atomic_thread_fence(std::memory_order_release);
```

ex. 앞선 예제에 획득-해제 의미론 적용

```cpp
std::atomic<bool> is_enemy_coming(false);
int enemy_num = 0;

// 주유왕 스레드
void thread_zhouyouwang()
{
	enemy_num = 10000;
	
	//해제 장벽
	std::atomic_thread_fence(std::memory_order_release);
	
	// memory_order_relaxed: 변수 원자성 확보하면 충분. 명령어 재정렬 등의 추가적인 제한을 두지 않음
	is_enemy_coming.store(true, std::memory_order_relaxed); 
}

// 제후 스레드
void thread_zhuhou()
{
	int n;
	
	if (is_enemy_coming.load(std::memory_order_relaxed))
	{
		// 획득 장벽
		std::atomic_thread_fence(std::memory_order_acquire);
		
		n = enemy_num;
	}
}
```

### 5.4.6 다른 CPU, 다른 천성

> 아키텍처별로 가지는 명령어 재정렬
> 

모든 유형의 CPU에 4가지 명령어 재정렬이 존재하지는 않음

**약한 메모리 모델 (weak memory model)**

모든 유형의 명령어 재정렬 존재

Ex. Alpha, ARMv7, POWER 등의 CPU

**강한 메모리 모델 (strong memory model)**

자체적인 획득-해제론이 존재해 적은 재정렬이 존재하는 CPU

Ex. x86은 StoreLoad 재정렬만 존재



### 5.4.7 누가 명령어 재정렬에 관심을 가져야 하는가: 잠금 없는 프로그래밍

> 잠금 없는 프로그래밍을 할 때에만 명령어 재정렬 신경 쓰면 됨
> 

**잠금 없는 프로그래밍**

공유 변수가 잠금 보호 없이 여러 스레드에서 사용

운영 체제가 어떻게 순서 스케줄링을 하든 스레드 하나는 무조건 앞으로 나아갈 수 있는 스레드 확보 가능

이러한 운영 체제의 특징

스레드 하나가 운영 체제에 의해 중지되더라도 다른 스레드가 블로킹되어 계속 실행되지 않는 문제가 발생하지 않음

**잠금**

일반적인 다중 스레드 프로그래밍은 공유 변수를 보호하기 위해 잠금 사용

잠금을 유지하는 스레드가 운영 체제에 의해 일시 중지된 후 잠금이 필요한 모든 다른 스레드는 앞으로 나아갈 수 없음

잠금을 사용해 프로그래밍하는 경우 잠금이 명령어 재정렬 문제를 자동으로 처리

- 모든 메모리 작업은 반드시 임계 영역 내에서 실행되기를 기다림
- 임계 영역이 너무 커서는 안 됨


즉, 잠금 없는 프로그래밍이 잠금을 사용하는 프로그래밍보다 더 효율적이라고 생각할 수 있지만 그렇지 않음 !

### 5.4.8 잠금 프로그래밍과 잠금 없는 프로그래밍

> 잠금을 이용한 프로그래밍: Mutual Exclusion, Spinlock
> 

**잠금 (Lock) 종류**

Mutual Exclusion(Mutex): 다중 스레드 프로그래밍에서 일반적으로 Mutual Exclusion(상호배제)가 공유 리소스 보호에 사용됨

- 동시에 최대 하나의 스레드만 Mutual Exclusion 보유 가능
- 잠금이 사용되면 해당 잠금을 요청하는 다른 스레드는 운영 체제에 의해 대기 상태로 있으며, 잠금을 사용한 스레드가 잠금 해제할 때까지 대기

Spinlock: 잠금이 사용된 후 잠금을 요청하는 스레드는 계속 잠금이 해제되었는지 여부 확인

- 잠금을 요청하는 스레드가 대기 상태로 진입하지 않음

**잠금 프로그래밍 특징**

잠금을 사용하고 있을 때 잠금을 요청하는 다른 스레드는 반드시 그 자리에서 대기

- Mutual Exclusion은 운영 체제가 대기 상태로 만들고, Spinlock은 반복적으로 검사하는 등 앞으로 나아갈 수 없음

**잠금 없는 프로그래밍**

시스템 성능 향상에 사용되지 않고, 스레드가 항상 대기 없이 어떤 일을 하도록 하는 것에 가치를 둠

장점

- 실시간 요구 사항이 높은 경우 유리
- 간단한 특정 상황에서는 적은 수의 원자적 작업으로 구현 가능하며, 이 경우 잠금 없는 프로그래밍의 성능이 더 좋을 수 있음

단점

- 매우 많고 복잡한 리소스 경쟁 문제와 ABA 문제 처리해야 하며, 코드 구현 복잡

### 5.4.9 명령어 재정렬에 대한 논쟁

> 명령어 재정렬을 해결하기 위해 메모리 장벽을 사용할 수밖에 없는가
> 

하드웨어 엔지니어 입장

- 명령어 재정렬은 CPU 성능 향상에 도움
- BUT 매우 어렵고 많은 버그 발생 가능성 존재

소프트웨어 엔지니어 입장

- CPU 성능에 영향을 미치지 않는다면 하드웨어 내부에서 해결하는 것이 좋음

잠금 없는 프로그래밍을 할 필요가 없다면 5장은 생각하지 않아도 됨

**중요 포인트**

1. 성능을 위해 CPU는 반드시 프로그래머가 코드를 작성한 순서대로 엄격하게 기계 명령어를 실행할 필요 없음
2. 프로그램이 단일 스레드인 경우 명령어의 비순차적 실행을 볼 수 없으므로, 단일 스레드 프로그램은 명령어 재정렬에 신경 쓸 필요 없음
3. 메모리 장벽의 목적은 특정 코어가 명령어를 실행하는 순서와 다른 코어에서 보이는 순서가 코드 순서와 일치하도록 만드는 것
4. 멀티 스레드 잠금 없는 프로그래밍을 사용할 필요가 없다면 명령어 재정렬 걱정할 필요 없음

## 5.5 요약

캐시로 인한 성능 향상

캐시 친화적인 프로그램

- 캐시 용량이 제한되어 있으므로 필요한 데이터에 더 “집중”해야 함
- 여러 스레드 사이에 캐시 일관성을 유지할 필요가 있다면 다중 스레드 프로그래밍에서의 캐시 튕김 문제 경계해야 함

명령어 재정렬 문제는 다중 스레드 기반의 잠금 없는 프로그래밍을 할 때 발생하며, 메모리 장벽으로 해결 가능

## 6.1 CPU는 어떻게 입출력 작업을 처리할까?

<aside>

CPU 내부에 레지스터가 있는 것과 마찬가지로, 장치에도 자체적인 레지스터인 “장치 레지스터(device register)” 존재

- CPU 레지스터
    - 메모리에서 읽은 데이터 임시 저장
    - CPU에서 계산한 중간 결과 저장
- 장치 레지스터는 주로 장치에 관련된 일부 정보 저장
    - `데이터 저장 레지스터`: 사용자가 키보드의 키를 누르면 해당 레지스터에 저장
    - `제어 정보와 상태 정보 저장 레지스터`: 레지스터를 읽고 쓰는 작업을 이용해 장치 제어 및 장치 상태 조회 가능
</aside>

### 6.1.1 전문적으로 처리하기: 입출력 기계 명령어

> CPU에서 입출력 처리
> 

**CPU 내부의 기계 명령어**

CPU 내부에 산술 계산, 점프, 메모리 읽기와 쓰기 등과 같은 특정한 기계 명령어 존재

- 따라서 장치 레지스터를 읽고 쓰는 특정한 기계 명령어 설계 가능 ⇒ IN, OUT

### 6.1.2 메모리 사상 입출력

> CPU에서 입출력 구현 방식: 메모리 사상 입출력
> 

**어떤 장치 레지스터를 읽고 쓸지**

특정한 입출력 기계 명령어를 설계하는 방법 외에 장치를 작동시키는 방법

메모리를 읽고 쓰는 것처럼 장치 레지스터도 읽고 쓸 수 있지 않을까? 

- CPU가 LOAD와 STORE 명령어 실행 시 해당 명령어는 메모리를 읽고 쓰는 것인가 혹은 장치 레지스터를 읽고 쓰는 것인가 ⇒ 구별 불가능
- LOAD와 STORE 명령어는 메모리 주소 공간 전달
    - 이때 메모리 주소 공간은 실제 메모리 주소와 다른 개념
    - 기계 명령어 관점에서 CPU에 보이는 것은 주소 공간으로 해당 주소의 데이터가 어디에서 오는지 알 필요 없음
    - 주소 공간의 일부분을 장치에 할당 가능 ⇒ 주소 공간이 8비트이면, 아래와 같이 메모리와 장치 할당 가능 ⇒ “메모리 사상 입출력(Memory Mapping Input and Output)”



- 이 상황에서 CPU가 데이터 적재 명령어 실행 시 주소 0xf2에서 데이터를 읽도록 지정되어 있다고 가정
- CPU가 명령어 실행 시 내부의 하드웨어 논리가 해당 명령어가 전달하는 정보 감지
    - 앞의 4비트가 모두 1이면 해당 명령어는 장치를 대상으로 동작, 그렇지 않으면 일반적인 메모리 읽기 명령어로 동작

**컴퓨터 저수준 계층에서 입출력 구현 방법**

1. 특정 입출력 기계 명령어 사용
2. 메모리 사상 입출력 (Memory Mapping Input and Output)
    1. 메모리의 읽기와 쓰기 명령어 사용하고 주소 공간의 일부분을 장치에 할당

### 6.1.3 CPU가 키보드를 읽고 쓰는 것의 본질

> 입출력 시 CPU가 데이터를 어떻게 가져오는지, 읽을 시점을 어떻게 확인하는지
> 

**CPU가 키보드에서 데이터 가져오는 방법**

CPU가 키보드의 데이터를 읽는 데 명령어 하나로 충분

CPU가 키보드를 읽는 기계 명령어

- 메모리 사상 입출력 방식 채용
- 키보드 레지스터가 주소 공간의 0xfe00에 사상
    
    ⇒ Load 기계 명령어를 사용해 CPU 레지스터 값을 읽을 수 있음
    
    ```cpp
    Load R1 0xFE00
    ```
    

**키보드가 데이터를 읽을 시점 확인하는 방법**

CPU 동작 규칙과 외부 장치는 매우 다르며, 대다수의 장치는 사람이 조작하기 때문에 언제 마우스를 움직이고 키보드를 누를지 알 수 없음

⇒ “CPU는 특정한 방법을 사용해 장치의 작업 상태를 얻어야 함” ⇒ 장치 상태 레지스터의 역할

- 특정한 방법은 뒤에 나올 방식(Ex.폴링)

**장치 레지스터**

레지스터 값을 읽음으로써 CPU는 장치를 읽을 수 있는지 쓸 수 있는지 알 수 있음

### 6.1.4 폴링: 계속 검사하기

> 폴링 방식으로 장치 상태 레지스터를 계속 읽음으로써 키보드의 문자 읽기
> 

**장치 상태 레지스터**

장치 상태 레지스터를 지속적으로 읽는 작업으로 키보드를 누르면 바로 해당 키보드의 문자를 읽고, 누르지 않을 때는 계속 검사 반복할 수 있음

`BLZ 분기 점프 명령어`: 이전 명령어 결과가 0이면 지정된 위치로 점프

`BL 명령어`: 지정된 위치로 무조건 점프

**코드**

키보드에서 누른 키의 데이터를 저장하는 CPU 레지스터 주소 공간이 0xfe01

상태 레지스터는 주소 공간의 0xfe00 위치에 사상

```cpp
START
	Load R1 0xFE00 // 현재 키보드 상태 읽기
	BLZ START      // 현재 키보드 상태 레지스터 값이 0이면(키보드 누르지 X) 시작 위치로 점프. 현재 상태 다시 확인 (Loop)
	Load R0 0xFE01 // 키보드 누른 경우 상태 레지스터 값이 1이 되어 해당 명령어 실행 시작. 키보드 데이터가 R0 레지스터에 저장
	BL OTHER_TASK
```

위 코드를 고급 언어로 번역

```cpp
while (키가 눌리지 않음)
{
	//키가 눌릴 때까지 대기
}

키보드 데이터 읽기
```

위 입출력 구현 방법이 폴링 (polling)

**폴링 문제**

사용자가 키를 누르지 않는 경우 CPU가 항상 불필요하게 순환하며 대기

**폴링 개선 방식**

폴링은 “동기식 설계 방식”

- CPU는 누군가가 키를 누를 때까지 대기

개선하는 방법은 동기를 비동기로 바꾸는 것

### 6.1.5 배달 음식 주문과 중단 처리

> 폴링 방식에서 동기 → 비동기 전환
> 

**일반적인 인터럽트 처리 과정**

CPU가 특정 프로세스의 기계 명령어를 실행할 때 새로운 이벤트 발생

실행 중인 현재 작업의 우선순위가 인터럽트 요청보다 높은지 판단

인터럽트가 더 높다면 현재 작업 실행을 일시 중지하고 인터럽트 처리

인터럽트 종료 후 현재 작업으로 돌아옴

⇒ 프로그램은 끊임없이 실행되는 것이 아니라 언제든지 장치에 의해 실행 중단될 수 있음. BUT 이 과정은 프로그래머에게 드러나지 않으며 프로그램이 중단 없이 실행되고 있는 것처럼 느끼게 함


### 6.1.6 인터럽트 구동식 입출력

> 동기 기반의 폴링 → 비동기 인터럽트 처리로 변환
> 

**CPU 명령어 실행 방식: 인터럽트 구동식 입출력 (interrupt driven input and output)**

인터럽트 작동 방식에서 누군가가 키보드를 누르면 CPU를 중단하고, 인터럽트로 들어온 데이터를 얻음


⇒ 이 방식은 CPU 시간을 낭비하지 않으며, 장치에 데이터가 없는 경우 다른 작업을 실행하므로 폴링 방식보다 효율적

⇒ 프로그램 실행 상태를 저장하고 복원하는데 약간의 시간 낭비 존재하지만 이는 중단된 프로그램을 다시 실행하는데 반드시 필요

**해결되지 않은 문제**

1. CPU가 인터럽트 신호가 오는 것을 감지하는 방법
2. 중단된 프로그램의 실행 상태를 저장하고 복원하는 방법

### 6.1.7 CPU는 어떻게 인터럽트 신호를 감지할까?

> CPU가 인터럽트 신호 감지 방법
> 

**CPU**

CPU가 실행하는 기계 명령어에 하드웨어의 “인터럽트 신호 감지 단계” 필요

우선순위에 따라 인터럽트 처리 여부 결정

**인터럽트 처리 과정**

1. 인터럽트 처리 시 중단된 작업 상태 보존
2. 인터럽트 처리 함수의 시작 위치로 점프해 인터럽트 처리 함수 명령어 실행
3. 인터럽트 종료 후 원래 자리로 점프하여 중단된 작업 실행


### 6.1.8 인터럽트 처리와 함수 호출의 차이

> 인터럽트 처리와 함수 호출의 차이
> 

**인터럽트 처리**

점프와 반환 포함 ⇒ 일반 함수 호출과 유사

BUT 여기에서는 사용자 상태의 함수 호출만 고려한 것

**인터럽트 vs 함수 호출**

함수 호출

- 단일 스레드 내부에서만 발생하고, 동일한 실행 흐름 내에 존재
- 반환 주소, 일부 범용 레지스터 값, 매개변수 등의 정보 저장 필요

인터럽트

- 서로 다른 두 실행 흐름 내에 존재
- 함수 호출에 비해 점프 시 저장해야 할 정보가 많음

### 6.1.9 중단된 프로그램의 실행 상태 저장과 복원

> 중단된 프로그램 실행 상태 저장 및 복원 방법
> 

**여러 인터럽트 처리**

프로그램 A → 프로그램 B → 프로그램 C → 프로그램 D


순서: A → B → C → D → C → B → A

상태 저장 순서: A → B → C

복원 순서: C → B → A

메모리 상태 가정

1. CPU가 0x2008 번지에서 프로그램 A에 속하는 Load 명령어 실행
2. (인터럽트 발생 감지)
3. 프로그램 A에 필요한 정보 모두 저장 후 프로그램 B로 점프
    1. CPU는 커널 상태로 진입 & 프로그램 A에서 실행될 다음 기계 명령어 주소 (0x2009)와 프로그램 A 상태를 스택에 넣음 (push)
        
        
4. 인터럽트 실행 (B)
    1. 0x60000으로 점프
    2. 0x6002에서 OR 명령어 실행 시 인터럽트 발생 감지
5. 프로그램 B에 필요한 모든 정보 저장
    1. 다음 기계 명령어 주소인 0x6003과 프로그램 B의 상태를 스택에 넣음
        
        
6. 프로그램 C로 점프
    1. 위와 동일

        
7. 프로그램 D로 점프
    1. 인터럽트 없이 작업 마치기
8. 프로그램 D 종료 후 스택에서 가장 위의 데이터를 꺼내 (pop) PC 레지스터와 상응하는 상태 레지스터 복원
    1. 위 반복



## 6.2 디스크가 입출력을 처리할 때 CPU가 하는 일은 무엇일까?

<aside>

디스크가 입출력 처리할 때 CPU 개입은 필요하지 않음

</aside>

### 6.2.1 장치 제어기

> 디스크 입출력 시 CPU 개입이 필요 없는 이유: 입출력 장치의 장치 제어기
> 

**입출력 장치**

예시: 디스크

입출력 장치는 대체로 두 부분으로 나눌 수 있음

1. 기계 부분
    1. 입출력 요청이 들어올 때 읽어야 하는 데이터 탐색
    2. 디스크 입출력 시 매우 많은 시간을 소모하는 작업
        1. 기계 장치이기 때문에 CPU 속도와 비교하면 매우 느림
2. 전자 부분 (장치 제어기. device controller)
    1. 자체적인 프로세서와 펌웨어(firmware)
    2. CPU가 직접 도와주지 않는 상황에서도 복잡한 작업 가능
    3. 자신만의 버퍼와 레지스터를 갖추어 장치에서 읽은 데이터나 장치에 저장할 데이터 저장 가능

**장치 제어기 vs 장치 드라이버**

장치 제어기

- 장치 드라이버에서 명령을 받아 외부 장치를 제어하는 하드웨어
- 운영 체제에 해당하는 장치 드라이버와 외부 장치를 연결하는 다리 역할
- CPU 해방을 목적으로 점점 복잡해짐

장치 드라이버

- 운영 체제에 속한 코드



### 6.2.2 CPU가 직접 데이터를 복사해야 할까?

> 직접 메모리 접근으로 CPU 개입 없이 데이터 복사
> 

**장치 제어기와 데이터 복사**

장치 제어기는 어느 정도의 독립성과 자율성을 가지고 명령을 자체적으로 처리 가능

디스크 자체 버퍼로 데이터 읽은 후 장치 제어기 버퍼에 있는 데이터를 따로 메모리로 복사해야 할까?

→ NO

- CPU 입장에서 데이터 직접 복사는 계산 리소스를 극도로 낭비하는 일

CPU 개입 없이 직접 장치와 메모리 사이의 데이터 전송 방식 설계 ⇒ “직접 메모리 접근(Direct Memory Access)”

### 6.2.3 직접 메모리 접근

> 입출력 장치와 메모리 사이의 데이터 전송: 폴링, 인터럽트, 직접 메모리 접근
> 

**직접 메모리 접근**

CPU 개입 없이 메모리와 외부 장치 사이에서 데이터 전송

DMA가 원래 CPU가 하는 작업의 일부를 대신함



**직접 메모리 접근 과정**

1. CPU가 데이터 복사하는 방법을 알려주는 명령어를 DMA에 전달
    1. 메모리에서 장치로 데이터 기록할지 or 장치에서 메모리로 기록할지
    2. 얼마나 기록할지
    3. 어느 메모리 위치에서 데이터를 읽어야 하는지
    4. 어떤 장치에서 데이터를 읽고 쓸지
2. DMA는 자신의 목표를 명확히 하고 버스 중재 요청 후 장치 작동
    1. 버스 사용 권한 요청 → 장치 작동
    2. 디스크에서 데이터를 읽는다고 가정할 때 장치 제어기의 버퍼에서 데이터를 읽으면 DMA가 지정된 메모리 주소에 데이터 쓰는 방식으로 데이터 복사

ㄴ 메모리에서 장치로 데이터 쓰는 과정도 동일

**직접 메모리 접근 시 문제 발생**

가상 메모리와 캐시 지원 시스템에 문제 발생

1. 가상 메모리
    1. 가상 메모리 지원 시스템은 2 종류의 메모리 주소 존재: 가상 주소, 물리 주소
    2. DMA가 읽은 데이터를 가상 주소와 물리 메모리 주소 중 어느 쪽에 저장해야 하는가
        1. 해결책: 운영 체제가 DMA에 필요한 가상 주소와 물리 메모리 주소 사이의 사상 정보 제공
2. 캐시 일관성 문제
    1. 캐시가 존재하는 시스템에는 메모리의 데이터가 2개 있을 수 있고 둘이 다를 수 있음 (메모리에 하나, 캐시에 하나)
    2.  해결책: 상응하는 캐시의 데이터를 즉시 메모리에 갱신해 일관성 문제 해결
3. CPU가 데이터 전송이 완료되었는지 알 수 있는 방법
    1. DMA가 데이터 전송 완료하면 인터럽트 작동 방식으로 CPU에 알림

### 6.2.4 전 과정 정리

> 디스크 입출력 시 CPU 동작
> 
1. CPU로 실행되는 스레드 1에 입출력 요청
2. 운영 체제는 스레드 1의 실행 중지 & CPU를 스레드 2에 할당
3. 스레드 2 실행
4. 디스크가 동작하여 데이터 준비 완료되면 DMA 작동 방식이 직접 장치와 메모리 사이에서 데이터 전송
5. 인터럽트 작동 방식으로 CPU에 알림 & CPU는 스레드 2 중지 후 인터럽트 처리
6. 운영 체제는 스레드 1이 요청한 입출력 작업 처리를 확인하고 CPU에 스레드 1 할당

⇒ 핵심은 디스크가 입출력 요청 처리할 때 CPU가 기다리지 않고 운영 체제 스케줄링에 따라 스레드 2 실행



### 6.2.5 프로그래머에게 시사하는 것

1. 디스크의 입출력 요청 처리는 비동기 방식
2. 디스크의 입출력 요청 처리를 하나의 스레드로 간주하고 CPU가 기계 명령어를 실행하는 것도 스레드로 간주
    1. 입출력 요청이 오면 직접 디스크 스레드 생성해 작업 처리
    2. 이때 CPU 스레드와 디스크 스레드는 병행적으로 실행되고 비동기 방식으로 처리

## More

- 프로그래밍 언어가 하드웨어에서 실행되는 과정
    
    고급 언어 → (컴파일러) → 어셈블리어 → (어셈블러) → 기계어 → 바이너리 파일 → CPU 실행
    
    1. 고급 언어 (High-Level Language)
        1. 사람이 이해하기 쉬운 언어
        2. ex. C, C++, Python
        3. **고급언어 → 컴파일러 : “전처리 단계”**
        
        ```c
        int b = 3;
        int a = b+1;
        ```
        
    2. 컴파일러 (Compiler)
        1. 고급 언어를 저급 언어(어셈블리어 또는 기계어)로 번역하는 프로그램
        2. ex. gcc, clang, javac, rustc
        3. **컴파일러 → 어셈블리어 : “컴파일 단계”**
        
        ```bash
        gcc main.c -S #어셈블리어로 변환
        gcc main.s -c #목적 코드(.o) 생성
        gcc main.o -o main #바이너리 생성
        ```
        
    3. 어셈블리어 (Assembly Language)
        1. 기계어에 1:1 대응되는 사람이 읽을 수 있는 저급 언어
        2. CPU 아키텍처별로 다름 (x86, ARM)
        
        ```nasm
        movl $3, %ebx
        addl $1, %ebx
        ```
        
    4. 어셈블러 (Assembler)
        1. 어셈블리어를 기계어로 변환하는 도구
        2. **어셈블리어 → 기계어 : “어셈블 단계”**
        
        ```bash
        as main.s -o main.o #어셈블리 -> 목적 파일
        ```
        
    5. 기계어 (Machine Code)
        1. CPU가 직접 실행 가능한 이진수 코드
        2. ex. 1011000, 01100001과 같은 0과 1
        3. 사람이 읽기 매우 어렵고 하드웨어 종속적
        4. **기계어 → 바이너리 파일 : “링크 단계”**
    6. 바이너리 파일 (Binary File/Executable)
        1. 기계어 명령을 포함한 실행 가능한 파일
        2. ex. ELF(Linux), PE(Windows), Mach-O(macOS)
        3. **실행 가능한 바이너리 파일 → CPU에서 실행 : “실행 단계”**
        
        ```bash
        ./a.out #기계어가 담긴 a.out 바이너리 실행
        ```
        
- 어셈블리어
    
    기계어와 일대일 매칭이 되는 명령어로, 어셈블리어 명령어 하나가 기계(하드웨어)에 직접적인 명령을 내림
    
    기계어를 보기 좋게 한 것이 어셈블리어
    
    “ 고급 언어 (ex.Python) → 어셈블리어&기계어 ”
    
    고급 언어를 컴파일러로 컴파일한 후의 언어가 어셈블리어
    
    구성
    
    - 연산
        - 의미 있는 영문자의 약어
        - ex. add, sub, mov
    - 오퍼랜드
        - 레지스터, 상수, 메모리
    
    예시
    
    - mem의 값을 eax에 복사하는 명령
        
        ```nasm
        //mov [주소], [레지스터]
        mov eax, mem
        ```
        
- gcc & objdump
    
    gcc (GNU Compiler Collection)
    
    - GNU 프로젝트의 일환으로 개발되어 널리 쓰이고 있는 컴파일러
    - “기본 컴파일 옵션”이란 특별한 옵션을 지정하지 않고 컴파일했을 때의 기본 설정
        - `gcc main.c -o main`
    - 옵션
        
        
        | 옵션 | 정의 |
        | --- | --- |
        | -o | 지정한 파일명으로 실행 파일 저장 |
        | -E | 전처리 단계 수행 후 컴파일 과정을 거치지 않음
        실행 결과는 standard output에 출력 |
        | -S | 컴파일 단계 수행 후 어셈블 과정 거치지 않음 |
        | -c | 소스 코드를 컴파일 또는 어셈블하며, 링크하지 않음
        파일명으로 오브젝트 파일 생성 |
        | -I (i) | 디렉토리명에서 헤더 파일 검색 |
        | -l (L) | 라이브러리 파일과 링크
        접미사나 확장자(.a/.o)가 없어도 링크 |
        | -L | 디렉토리 내에서 라이브러리 파일 탐색 |
        | -D | 매크로 상수를 정의하기 위한 옵션 |
        | -O2 | 코드를 빠르게 실행되도록 최적화하는 옵션 |
    
    objdump
    
    - ELF 바이너리 분석 도구
        - ELF: 유닉스 계열 운영체제의 실행 파일에 사용되는 바이너리 파일 규격
    - 바이너리 파일을 사람이 읽을 수 있게 어셈블리 코드로 디스어셈블하거나 내부 구조 출력하는 도구
    - `objdump -d main`
    
    gcc 기본 옵션 + objdump 사용
    
    - 특별한 컴파일 옵션 없이 프로그램 빌드
    - 생성한 바이너리 objdump로 분석